\section{Проблема применимости помехоустойчивого кодирования в каналах связи, модели помех.} \label{chapt1_Problem}

-потребность в решении обратной задачи

-- добавить определение
Будем говорить, что реальный канал
передачи данных находится в \emph{фиксированном физическом состоянии}, если основные параметры
его помеховой обстановки относительно стабильны.

\subsection{Цифровые системы передачи данных.}\label{chapt1_digital_systems}

Приведем необходимые сведения о цифровых системах передачи данных (см., например, \cite{DeMoMet1}, \cite{DeMoMet2}, \cite{Prokis}). Основную задачу теории и техники связи составляет передача сообщений из одного пункта в другой.

Совокупность передатчиков, приемников и каналов, обеспечивающих обмен сообщениями между пунктами связи, называют \textit{системой передачи информации} или \textit{системой связи} (см. рис. 2).

Поясним функциональную схему и основные элементы цифровой системы связи. Выход источника $S(t)$ может предсталять собой как аналоговый, так и цифровой сигнал. Под цифровым сигналом понимается дискретный по времени и имеющий конечное число выходных значений сигнал. В системе цифровой связи сообщения, выданные источником, преобразуются в последовательность двоичных символов $b(t)$. Процесс эффективного преобразования выхода источника –- как аналогового, так и цифрового -– в последовательность двоичных символов называют кодированием источника или сжатием данных.

Последовательность двоичных символов от кодера источника поступает на кодер канала. Цель кодера канала состоит в том, чтобы ввести управляемым способом некоторую избыточность в информационную последовательность $b(t)$, которая может использоваться в приёмнике, чтобы преодолеть воздействие шума и интерференции, возникающее при передаче сигнала по каналу. Фактически избыточность в информационной последовательности помогает приёмнику в декодировании переданной информационной последовательности.

Полученная на выходе кодера канала двоичная последовательность $b_R(t)$ поступает на вход цифрового модулятора, который служит интерфейсом к каналу связи. Практически все каналы связи, применяющиеся на практике, способны к передаче электрических сигналов. В таких каналах основная цель цифрового модулятора сводится к отображению информационной двоичной последовательности $b_R(t)$ в соответствующий сигнал $u(t)$. Например,если кодированная информационная последовательность должна передать один бит за определённое время с постоянной скоростью $R$ бит/с, цифровой модулятор может отображать двоичный символ $0$ в сигнал $u_0(t)$, а двоичный символ $1$ – в сигнал $u_1(t)$, т.е. каждый бит передаётся отдельно.  Такая модуляция носит название  двоичной. Алтернативный вариант модулятора может передавать $n$ кодированных информационных битов одновременно, используя различные сигналы $u_i(t)$, $i=0, …, M-1$, один сигнал для каждого из $M=2n$ возможных $n$-битовых последовательностей. Этот вариант модуляции называется $М$–позиционной модуляцией $(M>2)$.

\textit{Каналом} связи называют совокупность средств передачи информации, включающую в себя физическую среду. При беспроволочной связи в качетсве физической среды выступает атмосфера. Телефонные каналы  используют ряд физических сред, таких как линии проводной связи, волоконно-оптические кабели и беспроволочные линии. Для любой физической среды, используемой для передачи информации, существенно, что передаваемый сигнал подвержен случайным искажениям через такие механизмы, как воздействие аддитивного теплового шума, генерируемого электронными устройствами, воздействие промышленных помех, воздействие атмосферных помех и т.п.

На приёмной стороне системы цифровой связи цифровой демодулятор обрабатывает искажённый каналом передаваемый сигнал $u^*(t)$ и преобразует его в последовательность чисел $b^*_R(t)$, которые представляют оценки переданных данных (двоичных или $М$-позиционных). Эта последовательность чисел поступает на канальный декодер, который пытается восстановить первоначальную информационную последовательность, используя знание канального кода и избыточности, содержащейся в принятых данных. При невозможности принять достаточно надежное решение относительно какой-либо позиции декодер (? решающее устройство) может выдать сигнал стирания, означающий отказ от решения.

Мера качества работы демодулятора и декодера -– это частота, с которой возникают ошибки декодируемой последовательности. Более точно, средняя вероятность ошибки на бит для выходных символов декодера является удобной характеристикой качества демодулятора-декодера. Вообще говоря, вероятность ошибки является функцией от характеристик кода, форм сигналов, используемых для передачи информации по каналу, мощности передатчика, характеристик канала, а именно уровня шума, природы интерференции и т.д., и методов демодуляции и декодирования.

На заключительной стадии, когда рассматривается аналоговый выход, декодер источника принимает выходную последовательность $b^*(t)$  от декодера канала и, используя знание метода кодирования источника, применённого на передаче, пытается восстановить исходную форму сигнала источника $S^*(t)$. Ошибки декодирования и возможные искажения в кодере и декодере источника приводят к тому, что сигнал на выходе декодера источника является аппроксимацией исходного сигнала источника.

Ниже приведем описание некоторых каналов связи.

 \textit{Проводные каналы.}
 Телефонная связь активно использует проводные линии для передачи звуковых и видео сигналов, а также других данных. Витые проводные пары и коаксиальный кабель дают электромагнитный канал, который обеспечивает прохождение относительно умеренной полосы частот. Сигналы, передаваемые через такие каналы, обычно искажаются по амплитуде и фазе, и, кроме того, на них накладывается аддитивный шум. Проводная линия связи в виде фитой пары также склонна к интерференции переходных помех от расположеннных рядом пар.

\textit{Волоконно-оптические каналы.}
 Стекловолокно предоставляет проэктировщику ширину полос, которая на несколько порядков больше, чем у каналов с коаксиальным кабелем.Передатчиком или модулятором в волоконно-оптической системе связи является источник света, светоизлучающий диод или лазер. Информация передается путем изменения (модуляции) интенсивности источника света посредством сигнала сообщения. Свет распространяется через волокно как световая волна, и она периодически усиливается вдоль тракта передачи, чтобы компенсировать затухание сигнала. В приемнике интенсивность детектируется с помощью фотодиода, чей выход является электрическим сигналом, который изменяется пропорционально мощности света на входе фотодиода. Источники шума в волоконно-оптических каналах -- это фотодиоды и электронные усилители.

\textit{Беспроводные (радио) каналы.}
  В системах беспроводной связи (радио связи) электромагнитная энергия передается в среду распространения антенной, которая служит излучателем. Способы распространения электромагнитных волн в атмосфере и в свободном пространстве разделяют на три категории: распространение поверхностной волной, распространение пространственной волной, распространение прямой волной.
  В диапазоне очень низких частот и звуковом диапазоне земля и ионосфера образуют волновод для распространения электромагнитных волн. Эти диапазоны используются прежде всего для решения навигационных задач. Доминирующий тип шума в этих диапазонах обусловлен грозовой деятельностью вокруг земного шара. Интерференция возникает из-за большого числа станций в этих диапазонах частот.

  Распространение земной волны является основным видом распространения в полосе средних частот. Это диапазон частот, используемый для с AM и морского радиовещания. Атмосферные шумы, промышленные шумы и тепловые шумы от электронных компонентов являются основными причинам искажения сигнала в этих частотах.

Частным случаем распространения пространственной волны является ионосферное распространение, которое сводится к отражению передаваемого сигнала от ионосферы, которая состоит из нескольких слоёв заряженных частиц, расположенных на высоте 50…400 км от поверхности земли. В дневное время суток разогрев нижних слоёв атмосферы солнцем обусловливает появление нижнего слоя на высоте ниже 120 км. Эти нижние слои, особенно D-слой, вызывают поглощение частот ниже 2 МГц, таким образом ограничивая распространение ионосферной волной радиопередач АМ радиовещания. Однако в течение ночных часов электронная концентрация частиц в нижних слоях ионосферы резко падает, и частотное поглощение, которое встречается в дневное время, значительно сокращается. Как следствие, мощные радиовещательные сигналы с АМ могут распространяться на большие расстояния посредством отражения от ионосферных слоев (которые располагаются на высоте от 140 до 400 км над поверхностью земли), и земной поверхности.

Часто возникающая проблема при ионосферном распространении электромагнитной волны в частотном диапазоне ВЧ – это многопутёвость. Многопутёвость образуется потому, что передаваемый сигнал достигает приёмника по многим путям с различными задержками. Это обычно приводит к межсимвольной интерференции в системе цифровой связи. Более того, сигнальные компоненты, прибывающие по различным путям распространения, могут суммироваться таким образом, что это приводит к явлению, названному замираниями. Это большинство людей испытало при слушании отдалённой радиостанции ночью, когда ионосферная волна является доминирующим способом распространения. Аддитивный шум в ВЧ диапазоне – это комбинация атмосферных помех и теплового шума.

На частотах УВЧ диапазона и выше основным способом электромагнитного распространения волн является распространение в пределах прямой видимости (ППВ). Для земных систем связи это означает, что передающая и приемная антенны должны быть в прямой видимости с относительно малой преградой. По этой причине передача телевизионных станций в УВЧ и СВЧ диапазонах частот для достижения широкой зоны охвата осуществляется антеннами на высоких опорах. Доминирующий шум, ограничивающий качество системы связи в ВЧ и УВЧ диапазонах, – тепловой шум, создаваемый во входных цепях приемника, и космические шумы, уловленные антенной. На частотах в диапазоне СВЧ выше чем 10 ГГц при распространения сигнала главную роль играют атмосферные условия.

На частотах выше КВЧ (крайне высокие частоты) полосы мы имеем диапазон инфракрасного и видимого излучений – области электромагнитного спектра, который может использоваться для применения ППВ оптической связи в свободном пространстве. До настоящего времени эти диапазоны частот использовались в экспериментальных системах связи типа связи между спутниками.

 \textit{Системы хранения информации и системы поиска информации} активно используются при повседневной обработки данных. Такими системами яволяются магнитная лента, включая цифровую наклонно-строчную звукозапись, видеолента, магнитные, оптические и компакт- диски, используемые для хранения данных компьютера. Все эти системы хранения информации могут рассматриваться как каналы связи. Процесс запоминания данных на магнитной ленте или магнитном или оптическом диске эквивалентен передаче сигнала по телефону или радиоканалу. Процесс считывания и сигнальные процессы, используемые в системах хранения, чтобы восстанавливать запасенную информацию, эквивалентен функциям, выполняемым приемником в системе связи для восстановления передаваемой информации.

Аддитивный шум, издаваемый электронными контактами, и интерференция от смежных дорожек обычно представлены в сигнале считывания записанной информации точно так, как это имеет место в системе проводной телефонии или системе радиосвязи. Количество данных, которые можно хранить, ограничено размером диска или ленты и плотностью записи (числом битов, хранящихся на единице площади), которая может быть достигнута электронными системами и головками записи-считывания. Например, плотность упаковки   бит на квадратный сантиметр демонстрировалась в экспериментальной системе хранения на магнитном диске. (Текущие коммерческие магнитные изделия хранения достигают значительно меньшей плотности.) Скорость, с которой данные могут быть записаны на диске или ленте, и скорость, с которой информация может считываться, также ограничены механическими и электрическими подсистемами, входящими в систему хранения информации.
Кодирование канала и модуляция – существенные компоненты хорошо разработанной цифровой магнитной или оптической системы хранения. В процессе считывания сигнал демодулируется и его избыточность, введённая кодером канала, используется для исправления ошибок считывания.

Отметим, что информационные последовательности, передаваемые по каналу связи, вообще говоря не обязательно должны быть двоичными. Так канал называется \textit{q-ичным}, если алфавит канала имеет мощность $q$

$q$-ичный цифровой канал называется \textit{симметричным}, если в канале вероятность замещения символа $a$ каким-то другим символом $b$, отличным от $a$, от значения $b$ не зависит.

Говорят, что канал связи \textit{обладает памятью}, если на значение ошибки на текущей позиции влияют значения ошибок на нескольких предыдущих позициях. Наличие памяти в реальных каналах проявляется в группировании ошибок.

Каналы связи называют идеально \textit{синхронизированными}, если в них есть механизмы, позволяющие препятствовать влиянию ошибок типа выпадения и вставки символов.

Канал связи называется \textit{стационарным}, если его статистические характеристики не зависят от времени.

Реальные цифровые каналы связи в общем случае неидеально синхронизированы, нестационарны, несимметричны и имеют память, однако учесть при моделировании канала одновременно влияние всех этих факторов достаточно сложно. В дальнейшем будем рассматривать идеально синхронизированные, симметричные, нестационарные каналы с памятью.

Под \textit{помехой} в канале связи понимают любое нежелательное воздействие на сигнал, которое ухудшает достоверность воспроизведения передаваемых сообщений. Помехи разнообразны как по своему происхождению, так и по физическим свойствам. Различают случайные и специально организованные помехи. В зависимости от источника возникновения случайные помехи подразделяют, например, на промышленные, атмосферные, космические, помехи от посторонних радиостанций и каналов, внутренние шумы аппаратуры и др.

Не следует смешивать понятие помехи и ошибки. \textit{Ошибкой} в канале называют событие, состоящее в том, что воспроизводимая последовательность не совпадает с исходной. Очевидно, что ошибки вызываются помехами. Чтобы рассматривать ошибки как функцию времени, введем еще одно определение:

В ряде случаев (в частности, при анализе корректирующей способности кода) дискретный канал удобно описывать методами случайных процессов. Для каналов с идеальной синхронизацией вводится понятие некоторого условного источника ошибок или ошибок и стираний. Для краткости будем называть его \textit{источником ошибок}. Этот источник выдает дискретный случайный процесс $\{E_i\}$, который назовем \textit{последовательностью ошибок}. Каждая позиция $\{E_i\}$ складывается с соответствующей позицией входного процесса $\{B_i\}$ по определенному правилу. Схема канала, соответствующая таким представлениям приведена на рис. 2.

--рисунок 1.5. из Турина

-- тут уже появилась аддитивность

Символы $\{E_i\}$ в канале без стирания имеют значения $e=0,...,m-1$ и суммирование происходит по модулю $m$. В канале со стиранием $e=0,..,m-1,\theta$ и суммирование происходит по модулю $m$ для $e\neq \theta$ и по правилу $b\oplus\theta=\theta$ для $e= \theta$. Если $e_i=0$, то символ $b_i$ принимается правильно ($b^*_i=b_i$); если $e_i=\theta$, то $b_i$ стирается ($b^*_i=\theta$); если $e_i=1,..,m-1$, то $b_i$ принимается с ошибкой ($b^*_i\neq b_i, b^*_i\neq \theta$).

Реализация последовательности ошибок $\{E_i\}$ зависит от реализации помехи в непрерывном канале и реализации входного процесса $\{B_i\}$. В общем случае (несимметричный канал) статистика $\{E_i\}$, а следовательно, и верность передачи зависят от статистики помехи и статистики процесса $\{B_i\}$. При этом в стационарном канале при стационарной передаваемой последовательности $\{B_i\}$ последовательность ошибок также стационарна. В канале без памяти при независимости значений $b_i$ значения $e_i$ также независимы. В стационарном дискретном канале с конечной памятью статистика $\{E_i\}$ полностью определяется статистикой $\{B_i\}$ и матрицей переходных вероятностей.

Для проектирования реальных каналов удобно предварительно рассматривать имитационные модели этих каналов. Под \textit{имитационным моделированием} принято понимать воспроизведение процесса функционирования исследуемой системы с соблюдением логической и временной последовательности протекания процессов.

На рис.3 показана классическая структура абстрактной имитационной модели \cite{DeMoMet2}. Рассмотрим подробнее составляющие ее блоки. Блок имитации внешних воздействий (БИВВ) формирует реализации случайных или детерминированных процессов, имитирующих воздействия внешней среды на объект. Блок обработки результатов (БОР) предназначен для получения информативных характеристик исследуемого объекта, а необходимая для этого информация поступает из блока математической модели объекта (БММО). Блок управления имитационной модели (БУИМ) реализует способ исследования имитационной модели, основное назначение этого блока -- автоматизация процесса проведения имитационных экспериментов.

\begin{center}
\includegraphics[height=100mm]{/part1/channel2.png}

Рис.3. Структурная схема имитационной модели цифрового помехо-устойчивого канала связи.
\end{center}
%тут про другие блоки тоже написать

Рассмотрим более подробно блок имитации внешних воздействий (БИВВ), с помощью которого моделируется шум. Задача блока имитации внешних воздействий (БИВВ) рассматриваемой имитационной модели заключается в моделировании источника ошибок. Результатом работы этого блока является поток ошибок, который воздействует на передаваемые по линии связи данные.

Как уже было сказано, канал связи обеспечивает соединение передатчика и приемника. Физический канал может представлять собой двухпроводную линию, пропускающую электрический сигнал, или стеклволокно, которое переносит информацию посредствм модулированного светвого луча, или подводный канал океана, в котором информация передается аккустически, или свободное пространство, по которому несущий информационный сигнал излучается при помощи антенны. Кроме того, как каналы связи могут характеризоваться и другие среды -- например, средства хранения информации, такие как  магнитная лента, магнитные и оптические диски.

Общая проблема, возникающая при передаче сигнала через любой канал, -- аддитивный шум. Аддитивный шум часто создается внутри различных электронных компонентов, таких как резисторы и твердотельные устройства, используемых в системах связи. Такие шумы назвают тепловыми. Другие источники шума и интерференции могут возникать вне системы (например, переходные помехи от друних пользователей канала). Другие виды сигнальных искажений, которые могут встречаться при передаче сигнала по каналу, -- это затухание сигнала, амплитудные и фазовые искажения сигнала, искажение сигнала, связанное с многопутевым распространением волн.


\subsection{Оценка применимости схем помехоустойчивого кодирования в каналах связи.}
При использовании каналов связи необходимо учитывать возможность возникновения ошибок как при передаче, так и при хранении информации. Средством для обнаружения и исправления ошибок являются помехоустойчивые коды и их кодеки. В связи с необходимостью обеспечения высокого уровня качества связи возникает задача подбора для каждого конкретного наиболее эффективных методов и средств обнаружения и исправления ошибок. Для решения этой задачи необходимо иметь достаточный объем сведений о возможных помехах в канале и о корректирующих свойствах кода по отношению к ошибкам различной структуры. Однако подбор помехоустйчивого кодека к реальному каналу является сложной оптимизационной задачей. Поэтому эффективно проводить эксперименты с использованием имитационных моделей каналов с помехами и анализировать их результаты. Эта задача может быть решена в рамках информационной системы оценки применимости схем алгебраического помехоустойчивого кодирования(ИС ОПСАПК), разработанной в \cite{DeMoMet2}.

Под информационной системой оценки применимости схем алгебраического помехоустойчивого кодирования будем понимать \cite{DeMoMet2} систему, позволяющую на основе компьютерных имитационных экспериментов оценить корректирующие способности помехоустойчивых алгебраических кодеков по отношению к ошибкам различного типа и подобрать оптимальный по заданным параметрам кодек к конкретному каналу связи.

\begin{center}
\includegraphics[height=50mm]{/part1/shema_of_evaluation1.png}

Рис.4. Структурная схема ИС ОПСАПК.
\end{center}

Структурная схема информационной системы оценки применимости схем алгебраического помехоустойчивого кодирования представлена на рис.4. В основе системы лежит имитационная модель цифрового помехоустойчивого канала, рассмотренная в предыдущем разделе. Также в состав входят база данных БД, содержащая информацию об условиях и результатах проведенных имитационных экспериментов, и блок анализа записей базы данных БАЗ, который осуществляет работу с данными БД.

--подробнее из статьи

Рассмотрим основные задачи, которые позволяет решать описанная информационная система:

1) Обработка проверочных и порождающих матриц кода.

2) Модификация кодов и нахождение их параметров.

3) Изучение свойств декодеров (тестирование корректирующей способности кодека по отношению к одиночной ошибке, к пачке ошибок, оценка зависимости исправляющей способности кодека от структуры ошибок).

4) Изучение влияния перемежения.

5) Исследование быстродействия работы кодера и декодера (оценка времени работы одного алгоритма при разных ошибках и разных алгоритмов при идентичных ошибках).

6) Конструирование и оценка корректирующих способностей кодов, полученных с помощью методов комбинирования.

7) Согласование кодеков с каналом (подбор приемлемой модели источника ошибок, выбор подходящих кодеков, исследование корректирующих способностей кодеков при выбранной модели источника ошибок).

\subsection{Методы моделирования помех.}
Существует несколько основных подходов к математическому моделированию источников ошибок. В \cite{DeMoMet1}, \cite{Finaev}, \cite{Bloch} рассматривались три различные общие схемы их описания: схема описания источников ошибок на основе цепей Маркова (схема М); схема описания источников ошибок на основе процессов восстановления (схема В); схема описания источников ошибок на основе процессов накопления (схема Н). Подробно эти схемы рассматриваются в \cite{DeMoMet1}. Там же содержатся необходимые библиографические ссылки.

В работах \cite{Finaev}, \cite{Bloch} были сделаны выводы по сопоставлению рассмотренных моделей. Так утверждалось, что схемой М можно с любой степенью точности аппроксимировать статистику ошибок в любом стационарном канале. Схема В удобна для использования при имитационном моделировании, и многие существующие модели источников ошибок являются ее частными случаями. Она позволяет с достаточной точностью отразить закономерности возникновения ошибок. Схема Н учитывает возможность перекрытия различных мешающих воздействий и поэтому более наглядна физически и удобна при имитационном моделировании, хотя проведение аналитических расчетов по ней затруднительно. Следует отметить, что указать, какая из схем моделирования наиболее эффективно аппроксимирует реальную статистику ошибок с одной стороны и удобна для расчетов с другой стороны, сложно. Критерий выбора модели зависит от желаемой точности аппроксимации.

Несколько иной подход к моделированию источников ошибок, основанный на теории квазипериодических последовательностей случайных величин был предложен в \cite{DeMoRGUPS}, \cite{DeMoSevKav}. Результаты этой работы будут подробно рассмотрены далее в разделе 4.2. Здесь же стоит отметить лишь очевидные преимущества данного подхода. Описываемая в \cite{DeMoRGUPS}, \cite{DeMoSevKav} $QPn$-модель является достаточно общей моделью источника ошибок в том смысле, что она включает в себя как частные случаи многие известные модели. Кроме того, она позволяет моделировать различные случаи помеховой обстановки и генирировать потоки ошибок сложной структуры.

В \cite{BelChak} представлен еще один подход к моделированию источников ошибок. В данной работе разработана формально-грамматическая модель шума, позволяющая генерировать квазипериодический процесс на основе модификации атрибутной грамматики Д. Кнута.

Разработкой моделей источников ошибок занимались многие ученые: Э.Н. Гильберт, Е.О. Эллиот, Б.М. Игельник, В.И. Петрович, Б.Д. Фричман, В.М. Охорзин, В.О. Колпаков, В.Я. Турин, О.В. Попов, Ю.С. Чье и другие. Обычно математическая модель описывает некоторый очень узкий класс каналов, поэтому для исследования корректирующей способности кодека по отношению к различным типам ошибок при проведении имитационных экспериментов необходимо использовать несколько моделей источников ошибок. Это затрудняет проведение имитационных экспериментов, так как в их процессе приходится тестировать корректирующую способность кодеков для разных моделей и различных значений параметров моделей. Представляется более удобным построить общую модель источника ошибок канала, которая позволила бы моделировать различные случаи помеховой обстановки.

В настоящее время на практике активно применяются $q$-ичные каналы связи. Технические аспекты их реализации подробно описаны в \cite{Prokis} и \cite{Osmolovski}. В данной работе в разделе 4 будут рассмотрены различные модели источников ошибок для  $q$-ичных цифровых каналов.

В дальнейшем интерес для нас будут представлять модели, построенные на основе марковских цепей, поэтому рассмотрим отдельно некоторые из классических математических моделей источников ошибок этого типа.

\subsection{Описание источника ошибок на основе цепей Маркова}
Рассмотрим описание источника ошибок на основе цепей Маркова из \cite{Turin71}.

Имеется $K$-ичный процесс состояний ${C_i}$, $c_i=0,1,..., K-1$, представляющий собой простую цепь Маркова. Вероятность того или иного из двух возможных значений $e_i$ на данной позиции полностью определяется значением состояния $c_i$ на этой позиции:
$$P(e_0|e_{-1}...e_{-\nu}c_{\mu}...c_{-\nu})=P(e_0|c_0)=P(e|c)=\hat{\epsilon_c} \;\;\; (\mu,\nu\rightarrow \infty),$$
где $\hat{\epsilon_c}=1-\epsilon_c$ для $e=0$ и $\hat{\epsilon_c}=\epsilon_c$ для $e=1$.

Таким образом, статистика $\{E_i\}$ полностью определяется матрицей переходных вероятностей $p_{c_{-1}c_0}$ порядка $K$
\begin{equation}
\label{ch1_matr}
P=\|p_{c_{-1}c_0}\|=\left(
                      \begin{array}{cccc}
                        p_{00} & p_{01} & \ldots & p_{0,K-1} \\
                        p_{10} & p_{11} & \ldots & p_{1,K-1} \\
                        \vdots & \vdots & \ldots & \vdots \\
                        p_{K-1,0} & p_{K-1, 1} & \ldots & p_{K-1, 1} \\
                      \end{array}
                    \right)
\end{equation}
и значениями вероятности ошибки в каждом состоянии $\epsilon_0,...,\epsilon_{K-1}$. В частности, вероятность ошибки в канале записывается выражением
$$p_e=\sum\limits_{c=0}^{K-1} P_c\epsilon_c,$$
где $P_c=P_{c_0}$ -- финальные вероятности состояний, которые определяются по матрице \ref{ch1_matr} из системы уравнений:
$$\sum\limits_{c_0=0}^{K=1}P_{c_0}=1;$$
$$\sum\limits_{c_{-1}=0}^{K=1}P_{c_{-1}}p_{c_{-1}c_0}=P_{c_0};$$
где $c_0=0,..., K-1$, ($P_{c_{-1}}=P_{c_0}$, если $c_{-1}=c_0$).

Обычно состояния канала могут быть разделены на две группы, в одной из которых вероятности ошибок значительно ниже, чем во второй. Состояния первой группы условимся называть \"хорошими\", а состояния второй группы -- \"плохими\". В общем случае в различных состояниях вероятности ошибок $\varepsilon_c$ различны.

В ряде случаев можно полагать, что ошибки возможны только в плохих состояниях. Введение различных состояний с одинаковыми вероятностями ошибки позволяет отобразить группирование пакетов ошибок в более сложные структуры, а также полигеометрический характер распределения длин пакетов и промежутков.

Далее рассмотрим некоторые частные случаи моделей источников ошибок, описанных на основе цепей Маркова.

\subsubsection{Модель Гильберта.}

Рассмотрим канал, который может находиться в двух состояниях –- "хорошем" \; и "плохом". В "хорошем" \;
состоянии ошибки быть не может, а в "плохом" \; ошибки возникают с
некоторой вероятностью $\varepsilon$ . Последовательность состояний образует простую цепь
Маркова. Таким образом модель Гилберта соответствует схеме М с двумя состояниями.
Статистика последовательности ошибок ${e_i}$  определяется матрицей
переходных вероятностей
$$P=
        \left(\begin{array}{cccc}
           p_{00} & p_{01} \\
           p_{10} & a_{11}\\
        \end{array}\right)$$
и величиной $\varepsilon$.

Наложение условия $p_{01}<<p_{00}$,  $p_{10}<<p_{11}$ позволит отобразить группирование ошибок в пакеты. Граф переходных вероятностей для модели Гильберта представлен на рис.5.

\begin{center}
\includegraphics[height=50mm, width=150mm]{/part1/gilb.pdf}

Рис.5. Граф переходных вероятностей модели Гильберта.
\end{center}

Вероятность ошибки в канале определяется по формуле:
$$p_{\mathrm{er}}=\frac{\varepsilon p_{01}}{p_{01}+p_{10}}.$$
$p_{er}$ обычно меньше условной вероятности ошибки в пакете $\varepsilon$, поэтому $p_{01}<p{10}$.
Вероятность возникновения пакета ошибок с данного символа
$$p_{n}=\frac{p_{01}p_{10}}{p_{01}+p_{10}}.$$

Более поздней модификацией модели Гильберта является модель Гильберта-Эллиота, допускающая наличие ошибок  в
"хорошем" \; состоянии  канала. В этом случае помимо матрицы переходных вероятностей задаются условные вероятности  $\varepsilon_0$ и  $\varepsilon_1$. Вероятность ошибки определится по формуле
$$p_{er}=\frac{\varepsilon_0 p_{10}+\varepsilon_1 p_{01}}{p_{01}+p_{10}}.$$

\subsubsection{Модель Фричмана и Фричмана-Свободы.}
Модель Фричмана не предусматривает ограничения на число "хороших" \; и "плохих" \; состояний. Полагается, что в "хороших" \; состояниях невозможны ошибки, а в "плохих" \; невозможен правильный прием. Последовательность состояний образует простую цепь Маркова.
Частный случай модели Фричмана - модель Фричмана-Свободы предусматривает только одно "плохое" \; состояние, и переходы из "хороших" \; состояний в длугие "хорошие" \; невозможны. Матрица переходных вероятностей для модели Фричмана-Свободы с $N$ состояниями имеет вид:
$$P=
         \left(\begin{array}{ccccc}
           P_{11} & 0 & \ldots & 0 & P_{1N} \\
           0 & P_{22} & \ldots & 0 & P_{2N} \\
           \vdots & \vdots & \ddots & \vdots & \vdots \\
           0 & 0 & \ldots & P_{N-1,N-1} & P_{N-1,N}\\
           P_{N,1} & P_{N,2} & \ldots & P_{N,N-1}& p_{N,N}
        \end{array}\right).$$

Финальные вероятности "хороших" \; состояний определяются выражениями:
$$P_1=P_{N}\frac{P_{N1}}{P_{1N}};P_2=P_{N}\frac{P_{N2}}{P_{2N}};\ldots; P_{N-1}=P_{N}\frac{P_{N,N-1}}{P_N-1,N}.$$

Финальная вероятность плохого состояния, равная вероятности ошибки, определяется выражением:
$$P_N=(1+\frac{P_{N1}}{P_{1N}}+\frac{P_{N2}}{P_{2N}}+\ldots+\frac{P_{N,N-1}}{P_{N-1,N}})^{-1}=P_{\mathrm{er}}.$$

Модели Фричмана и Фричмана-Свободы позволяют отобразить группирование пакетов ошибок, распределение длин пакетов по этим моделям является геометрическим.

%\newpage
%============================================================================================================================

\section{Скрытые марковские и полумарковские модели.} \label{chapt1_HMM_HSMM}
\subsection{Теория дискретных цепей Маркова.}\label{chapt1_Markov_Chains}
%Дрейк, Рабинер, Гнеденко.
В настоящее время теория цепей Маркова представляет собой хорошо разработанный математический аппарат. В этом разделе с опорой на \cite{Gnedenko}, \cite{Shiryaev}, \cite{Drake}, \cite{Grinstead} мы рассмотрим только необходимые нам для дальнейшего изложения понятия и утверждения этой теории.

Рассмотрим систему, которая в произвольный момент времени может быть описана одним из N различных взаимоисключающих состояний $S=\{S_1, S_2, ..., S_N \}$. В соответствии с некоторым вероятностным правилом система может в некоторые моменты времени претерпевать изменения состояния. Моменты времени, в которые происходит изменение состояния системы, будем обозначать через $t=1,2,..$, а ее состояние в момент времени $t$ через $q_t$. Описанная система называется \textit{дискретной цепью Маркова первого порядка} (или \textit{простой цепью Маркова}), если для нее выполняется \textit{марковское свойство}:
$$P[q_t=S_j|q_{t-1}=S_i, q_{t-2}=S_k,...]=P[q_t=S_j|q_{t-1}=S_i]\eqno (1.1)$$

В дальнейшем мы будем рассматривать \textit{однородную цепь Маркова}, для которой вероятность в правой части (1.1) не зависит от времени. Назовем эту вероятность \textit{вероятностью перехода} и обозначим $a_{ij}$:
$$a_{ij}=P[q_t=S_j|q_{t-1}=S_i],\;\;\; 1\leq i,j\leq N.$$

Здесь первый индекс всегда будет означать номер предшествующего состояния, а второй -- показывать, в какое состояние перейдет система в последующий момент времени.

Полная вероятностная картина возможных изменений, осуществляющихся при переходе от предыдущего состояния к следующему, задается матрицей:
$$A=
        \left(\begin{array}{cccc}
           a_{11} & a_{12} & \ldots & a_{1N} \\
           a_{21} & a_{22} & \ldots & a_{2N} \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1} & a_{N2} & \ldots & a_{NN}
        \end{array}\right).$$

Переходные вероятности обладают следующими свойствами:
$$0 \leq a_{ij}\leq 1,$$
$$\sum_{j=1}^N a_{ij}=1.$$

Первое свойство вытекает из того, что элементы матрицы перехода являются вероятностями. Второе является следствием того, что в момент времени $t$ из состояния $S_i$ система перейдет в одно и только в одно состояние из множества состояний $S$. Таким образом, сумма элементов строки матрицы перехода равна единице.

Для полного описания однородной цепи Маркова необходимо, кроме матрицы переходов, задать еще вероятности состояния системы в начальный момент времени. Рассмотренный стохастический процесс может быть назван \textit{наблюдаемой марковской моделью}, поскольку выходом такого процесса в каждый момент времени является очередное состояние модели, которое соответствует физическому (наблюдаемому) событию.

При рассмотрении однородных цепей Маркова зачастую бывает удобно пользоваться графом состояний, на котором у стрелок выписаны соответствующие переходные вероятности. Такой граф принято называть \textit{помеченным графом состояний}(Рис. 1).

\begin{center}
  \includegraphics[height=100mm]{/part1/Markov_Chain.jpg}

  Рис.1. Помеченный граф состояний цепи Маркова с 5 состояниями и заданными вероятностями переходов между ними.
  \end{center}

Рассмотрим вероятность перехода из состояния $S_i$, в котором модель находится в момент времени $t$, в состояние $S_j$ через $n$ моментов времени. Обозначим эту вероятность $a_{ij}(n)$. Предположим, что в некоторый промежуточный момент времени $m$ система перешла в состояние $S_r$. Вероятность такого перехода в соответствии с введенными обозначениями будет равна $a_{ir}(m)$, а вероятность последующего перехода из состояния $S_r$ в $S_j$  в момент времени $n$ --- $a_{rj}(n-m)$. По формуле полной вероятности:
$$a_{ij}(n)=\sum\limits_{r=1}^N a_{ir}(m)a_{rj}(n-m)\eqno(1.2)$$

Обозначим $A_n$ матрицу перехода через $n$ моментов времени:
$$A_n=
        \left(\begin{array}{cccc}
           a_{11}(n) & a_{12}(n) & \ldots & a_{1N}(n) \\
           a_{21}(n) & a_{22}(n) & \ldots & a_{2N}(n) \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1}(n) & a_{N2}(n) & \ldots & a_{NN}(n)
        \end{array}\right).$$

Согласно (1.2) между матрицами $A_s$ с различными индексами существует соотношение:
$$A_n=A_m\cdot A_{n-m}, \;\;\; (0<m<n).$$

В частности, при $n=2$ находим
$$A_2=A_1\cdot A_1=A^2,$$
при $n=3$
$$A_3=A_1\cdot A_2=A\cdot A^2=A^3,$$
и вообще при любом $n$
$$A_n=A^n.$$

Отметим частный случай формулы (1.2) для $m=1$:
$$a_{ij}(n)=\sum\limits_{r=1}^N a_{ir}a_{rj}(n-1).\eqno(1.3)$$

Имеет место следующая теорема о предельных вероятностях \cite{Shiryaev}.

\textbf{Теорема 0}. Пусть $A=\{a_{ij}\}$ -- матрица переходных вероятностей марковской цепи с конечным множеством состояний $S=\{S_1,S_2,.., S_N\}$.

a) Если найдется $n_0$ такое, что
$$\min\limits_{i,j} a_{ij}(n_0)>0, \eqno(1.4)$$
то существуют числа $P_1, P_2,.., P_N$ такие, что
$$P_j>0, \;\;\; \sum\limits_j P_j = 1, \eqno(1.5)$$
и для любого $S_i\in S$
$$a_{ij}(n)\rightarrow P_j, \;\;\; n\rightarrow \infty. \eqno (1.6)$$

b) Обратно, если существуют чилсла $P_1, P_2,.., P_N$, удовлетворяющие условиям (1.4) и (1.5), то найжется $n_0$ такое, что выполнено условие (1.6).

c) Числа $P_1, P_2, .., P_N$ удовлетворяют системе уравнений
$$P_j = \sum\limits_{i=1}^N P_i a_{ij}, \;\;\; j = 1,..,N. \blacktriangle$$



Числа $P_j$ носят название \textit{предельных (или финальных)} вероятностей марковской цепи.

Теорема 0 также называется \textit{эргодической} теоремой, поскольку описывает широкий класс марковских цепей, обладающих свойством \textit{эргодичности}: пределы $P_j = \lim\limits_{n\rightarrow \infty} a_{ij}(n)$ не только существуют, не зависят от $i$, образуют распределение вероятностей $P_j\geq0, \;\;\; \sum\limits_j P_j= 1$, но и таковы, что $P_j>0$ при всех $j$ (такие распределения $P_j$ называются \textit{эргодическими}). Доказательство теоремы 0 приведено в \cite{Shiryaev}.

Таким образом предельные вероятности однородной цепи Маркова могут быть вычислены из следующией системы уравнений:
$$\left\{\begin{array}{c}
\sum\limits_{i=1}^{N}P_i=1\\
\sum\limits_{i=1}^N P_i a_{ij}=P_j, \;\;\; j=1,..,N.
\end{array}\right. \eqno(1.7)$$

\textbf{Замечание. }В \cite{Bellman} доказано, что система (1.7) разрешима единственным образом только в случае, если выполнено условие регулярности для  матрицы $A$:

1) у  матрицы $A$ нет характеристических чисел, отличных от единицы и равных по модулю единице;

2) единица является простым корнем характеристического уравнения матрицы $A$.

Однородная марковская цепь, у которой матрица переходов является регулярной (т. е. удовлетворяет 1) и 2)), называется \textit{регулярной}. Если матрица переходов удовлетворяет только 1), такая цепь называется \textit{правильной}.

\subsection{Скрытая марковская модель.}\label{chapt1_HMM_Def}
Расширим понятие дискретной марковской модели на случай, когда наблюдение представляет собой некоторую вероятностную функцию состояния \cite{Rabiner}. Мы получим дважды стохастический процесс, состоящий из пары случайных процессов, один из которых является основным и ненаблюдаемым (скрытым), а второй носит название выходного и дает последовательность наблюдений. Скрытый процесс реализуется дискретной марковской цепью, однако судить о нем возможно только по результирующей последовательности выходного процесса. Такую модель будем называть \textit{скрытой марковской моделью}.

Формально скрытая марковская модель(СММ) задается следующими параметрами:

1) алфавит скрытых состояний $S=\{S_1, S_2, ..., S_N \}$ мощности \emph{N};

2) матрица переходных вероятностей
$$A=
        \left(\begin{array}{cccc}
           a_{11} & a_{12} & \ldots & a_{1N} \\
           a_{21} & a_{22} & \ldots & a_{2N} \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1} & a_{N2} & \ldots & a_{NN}
        \end{array}\right),$$
где $a_{ij} = P[q_t=S_j|q_{t-1}=S_i]$, $q_t$ -- состояние модели в момент $t$;

3) вектор начального распределения вероятностей состояний
$$\pi=\{ \pi_1, \pi_2, …, \pi_N \},$$
где $\pi_i=P[q_1=S_i]$ ;

4) алфавит наблюдаемых символов $V=\{v_1,v_2,…,v_M \}$ мощности $M$;

5) матрица распределений вероятностей появления наблюдаемых символов:
$$B=
        \left(\begin{array}{cccc}
           b_{11} & b_{12} & \ldots & b_{1M} \\
           b_{21} & b_{22} & \ldots & b_{2M} \\
           \vdots & \vdots & \ddots & \vdots \\
           b_{N1} & b_{N2} & \ldots & b_{NM}
        \end{array}\right),$$
где $b_{jk}=b_j(k) = P[r_t= v_k | q_t = S_j]$, $r_t$ -- символ, наблюдаемый в момент времени $t$.

Для обозначения всего множества параметров модели будем использовать обозначение $\lambda=(A,B,\pi)$.

Предположим, что параметры СММ заданы, тогда построенную модель можно использовать в качестве генератора последовательности наблюдений $O=O_1O_2…O_T$, где каждое наблюдение $O_t$ является символом алфавита $V$, а $T$ -- число символов в наблюдаемой последовательности. Генерирование последовательности  $O=O_1O_2…O_T$  производится в два этапа:

 \textbf{Этап 1.} Выбирается состояние модели. В момент времени $t=1$ выбор состояния производится в соответствии с начальным распределением $\pi$, а в последующие моменты - в соответствии с матрицей $A$.

 \textbf{Этап 2.} В выбранном состоянии $S_i$ с использованием соответствующей строки матрицы $B$ генерируется наблюдаемый символ.

 Полученную последовательность наблюдений $O=O_1O_2…O_T$ будем называть последовательностью, \textit{порожденной моделью} $\lambda=(A,B,\pi)$.

-обзор (в том числе Ю.) Ю лучше всех
-чтобы использовать Ю нужны новые модели
%\subsection{Подход Ю к теории скрытых полу-марковских моделей} \label{subsect1_2_1}
\subsection{Общая скрытая полумарковская модель (ОСПММ)}\label{chapt1_GSHMM}
В работе Ю \cite{Yu} введено понятие общей скрытой полумарковской модели (ОСПММ) для описания некоторого класса систем, которые могут находиться в различных состояниях, генерировать символы выходного алфавита и осуществлять переходы между состояниями.

Временную ось будем считать дискретной и отождествлять с $\mathbb{Z}$. Через $X^n$ будем обозначать множество последовательностей длины $n$ над $X$, где $X$ --- некоторое конечное множество. Общая скрытая полу-марковская модель (ОСПММ) определяется как набор
$$\lambda = \{\mathcal{S}, \mathcal{D}, A, \Pi, \mathcal{V}, B \},$$
элементы которого описываются следующим образом.

$\mathcal{S}=\{1,...,N\}$ --- алфавит состояний дискретной полу-марковской цепи, а $\mathcal{D}=\{1,...,D\}$ --- алфавит возможных длительностей состояний. Элементы декартова произведения $\mathcal{S}\times\mathcal{D}$ будем называть, следуя \cite{Murphy}, обобщенными состояниями.

$A=\{a_{(i,d)(i^\prime,d^\prime)}\}_{(i,d),(i^\prime, d^\prime)\in \mathcal{S}\times \mathcal{D}}$ --- матрица переходных вероятностей для обобщенных состояний, то есть $a_{(i,d)(i^\prime,d^\prime)}$ --- это вероятность перехода из обобщенного состояния $(i,d)$ в обобщенное состояние $(i^\prime,d^\prime)$, при этом
\begin{equation}
\label{stoch_cond}
\forall (i,d)\in \mathcal{S}\times\mathcal{D}:\;\;\; \sum\limits_{i^\prime \in S\backslash\{i\}}\sum\limits_{d^\prime\in \mathcal{D}}a_{(i,d)(i^\prime,d^\prime)}=1,
\end{equation}
$$\forall i \in \mathcal{S},\forall d,d^\prime \in \mathcal{D}:\;\;\; a_{(i,d^\prime)(i,d)}=0.$$

$\Pi=\{\pi_{i,d}\}_{(i,d)\in \mathcal{S}\times \mathcal{D}}$ --- набор исходных распределений вероятностей обобщенных состояний, т.е. $\pi_{i,d}$  --- вероятность того, что система прибывала в обобщенном состоянии $(i,d)$ до начала наблюдений.

$\mathcal{V}=\{v_1,...,v_M\}$ --- алфавит наблюдаемых символов, $$B=\{b_{i,d}(\hat{o}_1,...,\hat{o}_d)\}_{(i,d) \in \mathcal{S}\times \mathcal{D}, (\hat{o}_1,...,\hat{o}_d) \in \mathcal{V}^d}$$ --- набор распределений вероятностей наблюдений последовательностей $(\hat{o}_1,...,\hat{o}_d) \in \mathcal{V}^d$ в обобщенных состояниях.

Заметим, что текущее состояние и длительность пребывания в нем зависят как от предыдущего состояния, так и от его длительности. Частными случаями ОСПММ являются скрытая марковская модель с явно заданной плотностью длительности состояний \cite{Rabiner}, скрытая марковская модель с непрерывно изменяющейся длительностью из \cite{Levinson}, а также сегментные скрытые марковские модели, обзор которых можно найти в \cite{Ostendorf}.

Следуя Ю, будем использовать следующие обозначения: $O_{t_1:t_m}\triangleq O_{t_1},...,O_{t_m}$, $S_{t_1:t_m}\triangleq S_{t_1},...,S_{t_m}$, где $t_1,...,t_m $ --- последовательность отсчетов времени $(t_i\in \mathbb{Z})$. Далее
  $S_{t_1:t_2}=i$ означает, что система находится в состоянии $i$ на протяжении временного интервала $[t_1,t_2]$. $S_{[t_1:t_2]}=i$ свидетельствует о том, что состояние $i$ начинается в момент времени $t_1$, продолжается на протяжении временного интервала $[t_1,t_2]$ и заканчивается в момент времени $t_2$.
 Обозначение $S_{[t_1:t_2}=i$ отражает ситуацию, когда состояние $i$ начинается в момент времени $t_1$, продолжается на протяжении $[t_1,t_2]$ и необязательно заканчивается в момент времени $t_2$. Аналогично, $S_{t_1:t_2]}=i$ означает, что система находилась в состоянии $i$ на протяжении $[t_1,t_2]$, причем началось состояние $i$ необязательно в момент $t_1$, но зато известно, что в момент $t_2$ состояние $i$ закончилось.
 Под $P[\alpha | \beta]$ будем понимать вероятность события $\alpha$ при условии выполнения события $\beta$, а под  $P[\alpha\cdot \beta]$  -- совместную вероятность наблюдения событий $\alpha$ и $\beta$.

 Используя введенные обозначения, можем записать:
$$\forall (i,d), (i^\prime,d^\prime)\in \mathcal{S}\times\mathcal{D}:\;\;\; a_{(i,d)(i^\prime,d^\prime)}\triangleq P[S_{[t+1:t+d^\prime]}=i^\prime|S_{[t-d +1:t]}=i],$$
где $t$ -- момент времени, когда произошел переход из обобщенного состояния $(i,d)$ в $(i^\prime,d^\prime)$;
\begin{equation}
\nonumber
\forall t\leq 0,\forall (i,d)\in \mathcal{S}\times\mathcal{D}:\;\;\; \pi_{i,d}\triangleq P[S_{[t-d+1:t]}=i];
\end{equation}
\begin{equation}
\begin{split}
\label{eq_firstb}
\forall (i,d) \in \mathcal{S}\times \mathcal{D},\forall (o_{t+1},...,o_{t+d}) &\in V^d :\\
&b_{i,d}(o_{t+1},...,o_{t+d})\triangleq P[ o_{t+1},...,o_{t+d}|S_{[t+1:t+d]}=i].
\end{split}
\end{equation}

\section{Обратные задачи в теории скрытых марковских и полумарковских моделей}\label{chapt1_Inverse_Problems}

...{Проблемы, связанные со скрытыми марковскими моделями.}...

В работе \cite{Rabiner} выделенные три основные проблемы, которые необходимо решить для того, чтобы скрытая марковская модель могла быть использована в практических задачах.

\textbf{Проблема 1.} Пусть задана последовательность наблюдений $O=O_1O_2…O_T$  и модель  $\lambda=(A,B,\pi)$. Как эффективно вычислить величину $P(O | \lambda)$, т.е. вероятность появления этой последовательности наблюдений для данной модели?

\textbf{Проблема 2.} Пусть заданы последовательность наблюдений $O=O_1O_2…O_T$  и модель  $\lambda=(A,B,\pi)$. Как выбрать последовательность состояний $Q = q_1q_2…q_T$, которая в некотором значимом смысле будет оптимальной (например, наилучшим образом соответствует имеющейся последовательности наблюдений)?

\textbf{Проблема 3.} Каким образом нужно подстроить параметры модели $\lambda=(A,B,\pi)$, для того чтобы максимизировать $P(O | \lambda)$?

Для нас особый интерес в дальнейшем будет представлять решение проблемы 1. Перефразируя формулировку, проблема 1 подразумевает, что известны модель и последовательность наблюдений. Требуется вычислить вероятность того, что наблюдения порождены заданной моделью. Далее будем говорить об этой прблемме как о \textit{задаче оценивания (evaluation problem)}.

 Можно рассматривать эту проблему как задачу выяснения, насколько хорошо некоторая модель подходит к имеющейся последовательности наблюдений. Так, например, ее решение оказывается полезным, когда возникает необходимость оптимального подбора модели из базы, наиболее точно имитирующей реальное поведение моделируемой системы. Поэтому для каждой модели $\lambda$ нужно уметь вычислять вероятности $P(O | \lambda)$ наблюдения экспериментально полученной последовательности $O=O_1O_2 ... O_T$ и сравнивать эти результаты для разных моделей.


Приведем алгоритм решения этой проблемы, впервые предложенный Баумом и описанный в \cite{Baum}, \cite{Rabiner}. Он носит название алгоритма \textit{прямого хода}.

Введем так называемую \textit{прямую} переменную $\alpha_t(i)$, определяемую выражением
$$\alpha_t(i) = P(O_1O_2…O_t ,q_t=S_i|\lambda).$$

Она представляет собой вероятность появления для данной модели частичной последовательности наблюдений $O_1O_2…O_t$  (до момента $t$ и состояния в этот момент). По индукции $\alpha_t(i)$ определяется следующим образом:

\textbf{Шаг 1.} Инициализация:
$$\alpha_1(i)= \pi_ib_i(O_1),	\;\;\; 1\leq i\leq N.$$

\textbf{Шаг 2.} Индуктивный переход:
\begin{eqnarray} \alpha_{t+1}(j)=[\sum_{i=1}^N \alpha_t(i)a_{ij}] b_j (O_{t+1} ),\nonumber \\
1\leq t \leq T-1, \;\;\; 1\leq j\leq N. \nonumber \\
\end{eqnarray}

\textbf{Шаг 3.} Окончание:
$$P[O|\lambda]=\sum_{i=1}^N \alpha_T(i).$$

Шаг 1 устанавливает значение прямой переменной равным совместной вероятности состояния и начального наблюдения $O_1$ . Индуктивный переход может быть проиллюстрирован следующим образом: $\alpha_t(i)$ представляет собой вероятность события, заключающегося в том, что наблюдается последовательность $O_1O_2\ldots O_t$, причем состояние в момент $t$ есть $S_i$, тогда произведение $\alpha_t(i) a_{ij}$ -- вероятность того, что в следующий момент $t+1$ будет достигнуто состояние $S_j$ . Суммирование этого произведения по всем возможным состояниям $S_i (1\leq i\leq N)$, в момент времени $t$ дает вероятность появления состояния $S_j$ в момент $t+1$ совместно со всеми предыдущими наблюдениями. Определив $S_j$, нетрудно далее убедиться в том, что $\alpha_{t+1}(j)$ получается посредством вычисления вероятности наблюдения $O_{t+1}$ в состоянии $j$, т. е. умножением результата суммирования на вероятность $b_j(O_{t+1})$.

Вычисления по индуктивной формуле при фиксированном $t$ выполняются для всех состояний $j$ ($1\leq j\leq N$) и при $t=1,2, \ldots, T-1$. На шаге 3 вычисляется искомая вероятность $P(O|\lambda)$ как сумма значений прямых переменных $\alpha_{T}(i)$. Это вытекает из того факта, что, по определению,
$$\alpha_{T}(i)=P(O_1 O_2\ldots O_T,q_T=S_i |\lambda).$$

Следовательно, $P(O|\lambda)$ является суммой по $i$ величин $\alpha_{T}(i)$.

\subsection{Решение задачи оценивания для общей скрытой полумарковской модели.} \label{chapt1_GHSMM_IP_Yu}
Рассмотрим теперь одну из классических задач теории скрытых марковских и скрытых полумарковских моделей, называемую задачей оценивания.

 Зафиксируем некоторую общую скрытую полумарковскую модель $\lambda = \{\mathcal{S}, \mathcal{D}, A, \Pi, \mathcal{V}, B \}$ и некоторую последовательность $O_{1:T}$ над алфавитом $\mathcal{V}$. Далее под задачей оценивания будем понимать задачу вычисления вероятности генерации последовательности $O_{1:T}$ данной моделью $\lambda$ при следующих предположениях, выделенных Ю (\cite{Yu}, с. 9999):

1) первое состояние началось в момент времени $t=1$ или до него;

2) последнее состояние закончилось строго в момент времени $T$.

Заметим, что в \cite{Yu} Ю выделил несколько различных вариантов предположений о начале и окончании последовательности наблюдаемых состояний, однако решение задачи оценивания предложил для упомянутого выше случая.

В дальнейшем будем обозначать искомую вероятность $P_{\lambda}[O_{1:T}]=P[O_{1:T}]$. Отметим, что эта вероятность рассматривается при фиксированной модели $\lambda$, однако для удобства далее мы будем, как правило, опускать значок $\lambda$ в обозначении этой величины. 

В работе \cite{Yu} предлагается подход к решению задачи оценивания, отличный от традиционного \cite{Rabiner},\cite{Levinson} и использующий понятие апостериорных вероятностей.

Именно, в \cite{Yu} вводится в рассмотрение величина $ \overline{\alpha}_t(i,d)$:
 \begin{equation}
\label{eq_posterior_alpha}
\forall 0<t\leq T, \forall (i,d) \in \mathcal{S}\times \mathcal{D}: \;\;\; \overline{\alpha}_t(i,d)\triangleq P[S_{[t-d+1:t]} = i| O_{1:t}],
\end{equation}
в терминах которой записывается рекуррентная формула для вычисления $P[O_{1:t}]$:
 \begin{equation}
\label{eq_finalprob}
P[O_{1:t}]=\sum\limits_{i\in \mathcal{S}}\sum\limits_{d \in \mathcal{D}} P[O_{1:t-d}]\overline{\alpha}_t(i,d)b_{i,d}(O_{t-d+1:t}),
\end{equation}
где, в свою очередь, $ \overline{\alpha}_t(i,d)$  вычисляется тоже рекурсивно:
 \begin{equation}
\label{eq_posterior_alpha_rec}
\overline{\alpha}_t(i,d) = \sum\limits_{i^\prime\in S \backslash \{i\}}\sum\limits_{d^\prime \in \mathcal{D}}\overline{\alpha}_{t-d}(i^\prime,d^\prime)\frac{b_{i^\prime,d^\prime}(O_{t-d-d^\prime+1}^{t-d})P[O_{1:t-d-d^\prime}]}{P[O_{1:t-d}]}a_{(i^\prime,d^\prime)(i,d)}.
\end{equation}

Таким образом, вероятность наблюдения полной последовательности $P[O_{1:T}]$ можно вычислять по формуле:
\begin{equation}
\label{eq_target_probability}
P[O_{1:T}]=\sum\limits_{i\in \mathcal{S}}\sum\limits_{d \in \mathcal{D}} P[O_{1:T-d}]\overline{\alpha}_T(i,d)b_{i,d}(O_{T-d+1:T}).
\end{equation}

Такой способ решения задачи оценивания позволяет избежать потери вычислительной точности в случае ОСПММ и поэтому может быть применен на практике \cite{Yu}.
%\newpage
%============================================================================================================================
%\subsection{Скрытая марковская модель с явно заданной плотностью длительности состояний (Модель Фергюсона) }
%
%Рассмотренная в разделе 1.2 классическая скрытая марковская модель представляет собой СММ с неявно заданной плотностью длительности состояний. Это означает, что плотность вероятности $p_i(d)$ пребывания в состоянии $S_i$ с переходной вероятностью $a_{ii}$ может быть вычислена как:
%   $$p_i(d)=a_{ii}^{d-1}(1-a_{ii})$$
%и равна вероятности $d$ последовательных наблюдений в состоянии $S_i$.
%
%Однако для большинства физических сигналов эта экспоненциальная плотность вероятности для длительности пребывания в состоянии является неприемлимой. Вместо этого длительность состояния предпочитают моделировать явно. В данном разделе мы рассмотрим \textit{скрытую марковскую модель с явно заданной плотностью длительности состояний}, описанную в \cite{Rabiner}(IV D). В ней дополнительно для каждого состояния $S_i$ задается функция плотности длительности пребывания в нем --- $p_i(d)$, где $d$ --- длительность пребывания в состоянии $S_i$, причем предполагается, что в момент завершения времени пребывания в каком-либо состоянии система не может снова перейти в него же.  Формально можно определить такую модель следующими параметрами:
%
%1) алфавит скрытых состояний $S=\{S_1, S_2, ..., S_N \}$ мощности \emph{N};
%
%2) матрица переходных вероятностей
%$$A=
%        \left(\begin{array}{cccc}
%           0 & a_{12} & \ldots & a_{1N} \\
%           a_{21} & 0 & \ldots & a_{2N} \\
%           \vdots & \vdots & \ddots & \vdots \\
%           a_{N1} & a_{N2} & \ldots & 0
%        \end{array}\right),$$
%где $$a_{ij} = P[q_t=S_j|q_{t-1}=S_i],$$
%$q_t$ - состояние модели в момент $t$;
%
%3) вектор начального распределения вероятностей состояний
%$$\pi=\{ \pi_1, \pi_2, \ldots , \pi_N \},$$
%где $$\pi_i=P[q_1=S_i];$$
%
%4) вектор, составленный из плотностей длительности пребывания в состояниях
%$$p(d)=\{ p_1(d), p_2(d),\ldots , p_N(d) \},$$
%где $d\in (1,..,D)$ - длительность пребывания в состоянии;
%
%5) алфавит наблюдаемых символов $V=\{v_1,v_2,\ldots ,v_M \}$ мощности M;
%
%6) матрица распределений вероятностей появления наблюдаемых символов:
%$$B=
%        \left(\begin{array}{cccc}
%           b_{11} & b_{12} & \ldots & b_{1M} \\
%           b_{21} & b_{22} & \ldots & b_{2M} \\
%           \vdots & \vdots & \ddots & \vdots \\
%           b_{N1} & b_{N2} & \ldots & b_{NM}
%        \end{array}\right),$$
%где $b_{jk}=b_j(k) = P[r_t= v_k | q_t = S_j]$, $r_t$ - символ, наблюдаемый в момент времени $t$.
%
%Тогда процесс генерирования последовательности наблюдений посредством такой модели будет выглядеть следующим образом.
%
% \textbf{Этап 1.} Как и в случае обыкновенной СММ, в соответствии либо с вектором $\pi$ (в момент времени $t=1$ ), либо с матрицей $A$ выбирается текущее состояние.
%
% \textbf{Этап 2.} В выбранном состоянии $S_i$ с использованием $p_i(d)$ определяется длина временного промежутка, в течение которого система будет находиться в $i$-ом состоянии, и в каждой точке этого отрезка посредством $b_i(k)$ генерируется наблюдение.
%
% Отметим, что в такой модели вероятность появления символа наблюдения внутри каждого состояния никак не зависит от времени, т. е. является постоянной на всем отрезке. По истечении времени пребывания системы в текущем состоянии, в соответствии с матрицей $A$ выбирается следующее состояние. Для удобства предполагается, что сразу вернуться в то же самое состояние система не может, т. е. $a_{ii}=0$.
%\section{....} \label{sect1_3}
%
%\subsection{...} \label{subsect1_3_1}
