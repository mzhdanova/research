\section{Скрытые марковские и полумарковские модели.} \label{chapt1_HMM_HSMM}
Теория скрытых марковских и полумарковских моделей представляет собой хорошо разработанный математический аппарат, получивший широкое применение в различных областях науки и техники. Эта теория предлагает весьма содержательные по своей математической структуре модели, которые могут составить теоретический фундамент для широкого круга приложений. Правильное применение этих моделей для решения некоторых важных прикладных задач приводит к очень хорошим результатам. Использование скрытых марковских и полумарковских моделей для описания источников ошибок представляется перспективным в силу того, что математическая структура этих моделей позволит описать сложную помеховую обстановку в канале нескольких физических состояний, а предлагаемые методы решения рассматриваемых теорией основных задач могут стать основой для решения обратной задачи, т.е. задачи подбора адекватной математической модели для описания ошибок в реальном канале связи.

Далее в этом разделе приведем краткий обзор теории скрытых марковских и полумарковских моделей.

\subsection{Скрытые марковские модели.}\label{chapt1_HMM_Def}
 С опорой на \cite{Rabiner}, \cite{Yu}, \cite{Drake}, \cite{Dymarski_11} рассмотрим необходимые для дальнейшего изложения сведения о скрытых марковских моделях.

 Первые заметки о теоретических аспектах скрытых марковских моделей были опубликованы Баумом в 1960-х. Начиная с 1970-ых годов скрытые марковские модели начали применяться для решения прикладных задач. Хронологически первым приложением теории стали задачи автоматического распознавания речи \cite{Rabiner}, \cite{Yu}; позднее популярность приобрела задача распознавания изображений, в частности, лиц \cite{Gultyaeva}, \cite{Djosan}. С середины 1980-х скрытые марковские модели начали применяться также в биоинформатике при анализе биологических последовательностей \cite{Fonzo}. В области защиты и передачи информации скрытые марковские модели нашли свое применение при построении систем обнаружения вторжений \cite{Khanna}, \cite{anikeev}, моделировании канала передачи данных с замираниями \cite{Turin98} и и разработке способа криптоанализа путем моделирования случайных контрмер побочного канала в виде скрытых марковских моделей, предложенный в \cite{Karlof}. Помимо перечисленных, теория СММ применяется в таких областях, как эконометрика, климатология, цифровая обработка сигналов, машинный перевод, и многих других. Причина популярности этого математического аппарата состоит в том, что он с одной стороны достаточно общий для моделирования большого числа реальных процессов с высокой точностью, а с другой стороны позволяет вычислять аналитически многие важные характеристики моделируемых процессов. Еще одним большим преимуществом использования этого подхода является существование для скрытых марковских моделей алгоритмов работы с экспериментальными данными.

Для того чтобы перейти к математическому описанию скрытых марковских моделей, приведем необходимые сведения из теории дискретных цепей Маркова из \cite{Gnedenko}, \cite{Shiryaev}, \cite{Drake}, \cite{Grinstead}.

Рассмотрим систему, которая в произвольный момент времени может быть описана одним из $N$ различных взаимоисключающих состояний $S=\{S_1, S_2, ..., S_N \}$. В соответствии с некоторым вероятностным правилом система может в некоторые моменты времени претерпевать изменения состояния. Моменты времени, в которые происходит изменение состояния системы, будем обозначать через $t=1,2,..$, а ее состояние в момент времени $t$ через $X_t$. Описанная система называется \textit{дискретной цепью Маркова первого порядка} (или \textit{простой цепью Маркова}), если для нее выполняется \textit{марковское свойство}:
\begin{equation}
\label{chapt1_markov_property}P[X_t=S_j|X_{t-1}=S_i, X_{t-2}=S_k,...]=P[X_t=S_j|X_{t-1}=S_i]
\end{equation}

В дальнейшем мы будем рассматривать \textit{однородную цепь Маркова}, для которой вероятность в правой части (\ref{chapt1_markov_property}) не зависит от времени. Назовем эту вероятность \textit{вероятностью перехода} и обозначим $a_{ij}$:
$$a_{ij}=P[X_t=S_j|X_{t-1}=S_i],\;\;\; 1\leq i,j\leq N.$$

Здесь первый индекс всегда будет означать номер предшествующего состояния, а второй -- показывать, в какое состояние перейдет система в последующий момент времени.

Полная вероятностная картина возможных изменений, осуществляющихся при переходе от предыдущего состояния к следующему, задается матрицей:
$$A=
        \left(\begin{array}{cccc}
           a_{11} & a_{12} & \ldots & a_{1N} \\
           a_{21} & a_{22} & \ldots & a_{2N} \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1} & a_{N2} & \ldots & a_{NN}
        \end{array}\right).$$

Переходные вероятности обладают следующими свойствами:
$$0 \leq a_{ij}\leq 1,$$
$$\sum_{j=1}^N a_{ij}=1.$$

Первое свойство вытекает из того, что элементы матрицы перехода являются вероятностями. Второе является следствием того, что в момент времени $t$ из состояния $S_i$ система перейдет в одно и только в одно состояние из множества состояний $S$. Таким образом, сумма элементов строки матрицы перехода равна единице.

Для полного описания однородной цепи Маркова необходимо, кроме матрицы переходов, задать еще вероятности состояния системы в начальный момент времени. Рассмотренный стохастический процесс может быть назван \textit{наблюдаемой марковской моделью}, поскольку выходом такого процесса в каждый момент времени является очередное состояние модели, которое соответствует физическому (наблюдаемому) событию.

При рассмотрении однородных цепей Маркова зачастую бывает удобно пользоваться графом состояний, на котором у стрелок выписаны соответствующие переходные вероятности. Такой граф принято называть \textit{помеченным графом состояний}(Рис. 6).

\begin{center}
  \includegraphics[height=100mm]{/part1/mchain.png}

  Рис.6. Помеченный граф состояний цепи Маркова с 5 состояниями и заданными вероятностями переходов между ними.
  \end{center}

Рассмотрим вероятность перехода из состояния $S_i$, в котором модель находится в момент времени $t$, в состояние $S_j$ через $n$ моментов времени. Обозначим эту вероятность $a_{ij}(n)$. Предположим, что в некоторый промежуточный момент времени $m$ система перешла в состояние $S_r$. Вероятность такого перехода в соответствии с введенными обозначениями будет равна $a_{ir}(m)$, а вероятность последующего перехода из состояния $S_r$ в $S_j$  в момент времени $n$ --- $a_{rj}(n-m)$. По формуле полной вероятности:
\begin{equation}\label{chapt1_aij}
	a_{ij}(n)=\sum\limits_{r=1}^N a_{ir}(m)a_{rj}(n-m)
\end{equation}

Обозначим $A_n$ матрицу перехода через $n$ моментов времени:
$$A_n=
        \left(\begin{array}{cccc}
           a_{11}(n) & a_{12}(n) & \ldots & a_{1N}(n) \\
           a_{21}(n) & a_{22}(n) & \ldots & a_{2N}(n) \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1}(n) & a_{N2}(n) & \ldots & a_{NN}(n)
        \end{array}\right).$$

Согласно (\ref{chapt1_aij}) между матрицами $A_s$ с различными индексами существует соотношение:
$$A_n=A_m\cdot A_{n-m}, \;\;\; (0<m<n).$$

В частности, при $n=2$ находим
$$A_2=A_1\cdot A_1=A^2,$$
при $n=3$
$$A_3=A_1\cdot A_2=A\cdot A^2=A^3,$$
и вообще при любом $n$
$$A_n=A^n.$$

Отметим частный случай формулы (\ref{chapt1_aij}) для $m=1$:
$$a_{ij}(n)=\sum\limits_{r=1}^N a_{ir}a_{rj}(n-1).$$

Имеет место следующая теорема о предельных вероятностях \cite{Shiryaev}.

\begin{theorem}\label{chapt1_theorem1} Пусть $A=\{a_{ij}\}$ -- матрица переходных вероятностей марковской цепи с конечным множеством состояний $S=\{S_1,S_2,.., S_N\}$\end{theorem}

a) Если найдется $n_0$ такое, что
\begin{equation}\label{chapt1_thoerem1_1}\min\limits_{i,j} a_{ij}(n_0)>0, \end{equation}
то существуют числа $P_1, P_2,.., P_N$ такие, что
\begin{equation}\label{chapt1_thoerem1_2}P_j>0, \;\;\; \sum\limits_j P_j = 1, \end{equation}
и для любого $S_i\in S$
\begin{equation}\label{chapt1_thoerem1_3}lim_{n\rightarrow \infty}a_{ij}(n)= P_j,.\end{equation}

b) Обратно, если существуют числа $P_1, P_2,.., P_N$, удовлетворяющие условиям (\ref{chapt1_thoerem1_1}) и (\ref{chapt1_thoerem1_2}), то найжется $n_0$ такое, что выполнено условие (\ref{chapt1_thoerem1_3}).

c) Числа $P_1, P_2, .., P_N$ удовлетворяют системе уравнений
$$P_j = \sum\limits_{i=1}^N P_i a_{ij}, \;\;\; j = 1,..,N. \blacktriangle$$

Числа $P_j$ носят название \textit{предельных (или финальных)} вероятностей марковской цепи.

Теорема 0 также называется \textit{эргодической} теоремой, поскольку описывает широкий класс марковских цепей, обладающих свойством \textit{эргодичности}: пределы $P_j = \lim\limits_{n\rightarrow \infty} a_{ij}(n)$ не только существуют, не зависят от $i$, образуют распределение вероятностей $P_j\geq0, \;\;\; \sum\limits_j P_j= 1$, но и таковы, что $P_j>0$ при всех $j$ (такие распределения $P_j$ называются \textit{эргодическими}). Доказательство теоремы 0 приведено в \cite{Shiryaev}.

Таким образом предельные вероятности однородной цепи Маркова могут быть вычислены из следующей системы уравнений:
\begin{equation}\label{chapt1_limit_propabilities}
\left\{\begin{array}{c}
\sum\limits_{i=1}^{N}P_i=1\\
\sum\limits_{i=1}^N P_i a_{ij}=P_j, \;\;\; j=1,..,N.
\end{array}\right.
\end{equation}

\begin{remark}В \cite{Bellman} доказано, что система (\ref{chapt1_limit_propabilities}) разрешима единственным образом только в случае, если выполнено условие регулярности для  матрицы $A$:

1) у  матрицы $A$ нет характеристических чисел, отличных от единицы и равных по модулю единице;

2) единица является простым корнем характеристического уравнения матрицы $A$.
\end{remark}

Однородная марковская цепь, у которой матрица переходов является регулярной (т. е. удовлетворяет 1) и 2)), называется \textit{регулярной}. Если матрица переходов удовлетворяет только 1), такая цепь называется \textit{правильной}.

Расширим понятие дискретной марковской модели на случай, когда наблюдение представляет собой некоторую вероятностную функцию состояния \cite{Rabiner}. Мы получим дважды стохастический процесс, состоящий из пары случайных процессов, один из которых является основным и ненаблюдаемым (скрытым), а второй носит название выходного и дает последовательность наблюдений. Скрытый процесс реализуется дискретной марковской цепью, однако судить о нем возможно только по результирующей последовательности выходного процесса. Такую модель будем называть \textit{скрытой марковской моделью}.

Формально скрытая марковская модель(СММ) задается следующими параметрами:

1) алфавит скрытых состояний $S=\{S_1, S_2, ..., S_N \}$ мощности \emph{N};

2) матрица переходных вероятностей
$$A=
        \left(\begin{array}{cccc}
           a_{11} & a_{12} & \ldots & a_{1N} \\
           a_{21} & a_{22} & \ldots & a_{2N} \\
           \vdots & \vdots & \ddots & \vdots \\
           a_{N1} & a_{N2} & \ldots & a_{NN}
        \end{array}\right),$$
где $a_{ij} = P[q_t=S_j|q_{t-1}=S_i]$, $q_t$ -- состояние модели в момент $t$;

3) вектор начального распределения вероятностей состояний
$$\pi=\{ \pi_1, \pi_2, …, \pi_N \},$$
где $\pi_i=P[q_1=S_i]$ ;

4) алфавит наблюдаемых символов $V=\{v_1,v_2,…,v_M \}$ мощности $M$;

5) матрица распределений вероятностей появления наблюдаемых символов:
$$B=
        \left(\begin{array}{cccc}
           b_{11} & b_{12} & \ldots & b_{1M} \\
           b_{21} & b_{22} & \ldots & b_{2M} \\
           \vdots & \vdots & \ddots & \vdots \\
           b_{N1} & b_{N2} & \ldots & b_{NM}
        \end{array}\right),$$
где $b_{jk}=b_j(k) = P[r_t= v_k | q_t = S_j]$, $r_t$ -- символ, наблюдаемый в момент времени $t$.

Заметим, что если наблюдения непрерывны, то вместо матрицы вероятностей наблюдений используется непрерывная функция плотности вероятности и задаются параметры этой функции.

Для обозначения всего множества параметров модели будем использовать обозначение $\lambda=(A,B,\pi)$.

\begin{center}
  \includegraphics[height=50mm]{/part1/hmm.png}

  Рис.7. Базовая структура скрытой марковской модели.
  \end{center}

Предположим, что параметры СММ заданы, тогда построенную модель можно использовать в качестве генератора последовательности наблюдений $O=O_1O_2…O_T$, где каждое наблюдение $O_t$ является символом алфавита $V$, а $T$ -- число символов в наблюдаемой последовательности. Генерирование последовательности  $O=O_1O_2…O_T$  производится в два этапа:

 \textbf{Этап 1.} Выбирается состояние модели. В момент времени $t=1$ выбор состояния производится в соответствии с начальным распределением $\pi$, а в последующие моменты - в соответствии с матрицей $A$.

 \textbf{Этап 2.} В выбранном состоянии $S_i$ с использованием соответствующей строки матрицы $B$ генерируется наблюдаемый символ.

 Полученную последовательность наблюдений $O=O_1O_2…O_T$ будем называть последовательностью, \textit{порожденной моделью} $\lambda=(A,B,\pi)$.

Одним из основных недостатков скрытых марковских моделей является используемый в них способ моделирования длительности состяний \cite{Rabiner}, \cite{Ostendorf}. Так, в случае скрытых марковских моделей плотность вероятности $p_i(d)$ пребывания в состоянии $S_i$ в течение $d$ моментов времени, с переходной вероятностью $a_{ii}$, имеет вид:
$$p_i(d)=(a_{ii})^{d-1}(1-a_{ii})$$
и таким образом представляет собой вероятность $d$ последовательных наблюдений в состоянии $S_i$. Однако, для большинства моделируемых систем такая экспоненциальная плотность вероятности для длительности прибывания в состоянии является неподходящей. В работе \cite{Ferguson} Джек Фергюсон предложил моделировать длительность состояния явно, а именно, ввел в рассмотрение скрытую марковскую модель с явно заданной плотностью длительности состояний. В этом случае модель попадает в некоторое состояние и находится в нем, порождая количество наблюдений, определенное в соответствии с функцией плотности длительности текущего состояния. Только после этого происходит переход в следующее состояние. Рисунок 3 иллюстрирует различия между СММ с неявно и явно заданными функциями плотности длительности состояний.

\begin{center}
  \includegraphics[height=100mm]{/part1/hsmm_hmm_comparison.png}

  Рис.8.Иллюстрация связей между состояниями: вверху обычная СММ с экспоненциальной плотностью вероятности длительности состояний; внизу СММ с явно заданной плотностью длительности состояний, не допускающая переходов "в себя".
  \end{center}

\subsection{Скрытые полумарковские модели}\label{chapt1_GSHMM}
Скрытые полумарковские модели представляют собой расширение скрытых марковских моделей, в котором скрытый процесс представляет полумарковскую цепь, что позволяет задавать произвольное распределение вероятностей длительностей состояний в отличие от скрытой марковской модели, в которой вероятность длительности состояний имеет геометрическое распределение.

Скрытые полумарковские модели были впервые предложены Джеком Фергюсоном в работе \cite{Ferguson}. Они рассматривались как альтернатива классическому подходу к моделированию речи на основе скрытых марковских моделей, поскольку последние показали себя недостаточно гибкими для описания времени нахождения в заданном состоянии. В последующие годы задачи, связанные со скрытыми полумарковскими моделями, исследовались такими авторами как Левинсон \cite{Levinson}, Гедон и Кокоцца-Тивент \cite{Guedon1990}, Гедон \cite{Guedon2003}, Сэнсом и Томсон \cite{SansomThomson2001}, Ю и Кобаяши \cite{YuKobayashi}. В этих работах рассматривались различные параметрические гипотезы для распределений длительности состояний также как и для распределений наблюдений.

В литературе скрытые полумарковские модели также называют скрытыми марковскими моделями с явно заданной плотностью длительности состояний (explicit duration HMM, HMM with explicit duration) \cite{Ferguson}, \cite{Rabiner},\cite{Mitchel1993}, скрытыми мароквскими моделями с изменяющейся длительностью (variable duration HMM) \cite{Levinson}, \cite{Rabiner}, \cite{RussellMoore1985}, скрытыми полумарковскими моделями \cite{Murphy}, обобщенными скрытыми марковскими моделями (generalized HMM)\cite{Kulp1996}, сегментными моделями (segment model) \cite{Ostendorf} в зависимости от предположений и области приложения.

Скрытые полумарковские модели широко применяются в различных областях, таких как распознавание речи \cite{Yu}, \cite{Rabiner}, распознавание печатного \cite{Amara1996} и рукописного текста \cite{Kundu1997}, распознавание человеческих генов в последовательности ДНК \cite{Kulp1996}, предсказание структуры белка \cite{Schmidler2000}, обнаружение аномалий в сети \cite{Yu2005}, моделирование финансовых временных рядов \cite{Bulla2006} и многих других.

Для дальнейшего приведем ниже краткое определение полумарковской цепи; более подробное описание можно найти в \cite{Kulkarni1995} и \cite{Korolyuk1976}. Заметим, что мы будем рассматривать здесь только полумарковские цепи без поглощающих состояний, т.к. скрытые полумарковские модели с поглощающими состояниями не подходят для прикладных задач. Кроме того, говоря о полумарковской цепи, будем понимать дискретную по времени полумарковскую цепь.

Рассмотрим систему с набором состояний $S=\{S_1, S_2, ..., S_n\}$. Пусть $X(t)$ -- состояние в момент времени $t$, $t\geq 0$. Будем предполагать, что система попадает в состояние $X_0$ в момент времени $r_0=0$. Она находится в нем случайное неотрицательное число моментов времени, после чего в момент времени $r_1$ переходит в другое состояние $X_1$, которое может быть тем же самым, что и $X_0$. Система остается в новом состоянии на протяжении другого неотрицательного случайного количества моментов времени, после чего переходит в следующее состояние $X_2$  в момент времени $r_2$ и т.д. Таким образом $r_m$ -- время $m$-того перехода, а $X_m$ -- $m$-тое состояние, в котором находилась система. Тогда $X(r_m)=X_m$.
Случайный процесс $\{X(t),t\geq 0 \}$ называется \emph{скрытым полумарковским}, если для каждого момента перехода $r_m$ выполняется марковское свойство.

Заметим, что из выполнения марковского свойства для полумарковского процесса $\{X(t),t\geq 0 \}$ следует выполнение марковского свойства для $\{X_n, n\geq 0 \}$ для любого $n\geq 0$. Таким образом, $\{X_n, n \geq 0 \}$ представляет собой однородную по времени дискретную марковскую цепь с пространством состояний $\{S_1, S_2,..., S_n\}$. Такая цепь называется встроенной (embedded) цепью Маркова скрытого полумарковского процесса.

Приведем определение общей скрытой полумарковской модели (ОСПММ), введенной Ю \cite{Yu} для описания некоторого класса систем, которые могут находиться в различных состояниях, генерировать символы выходного алфавита и осуществлять переходы между состояниями.

Временную ось будем считать дискретной и отождествлять с $\mathbb{Z}$. Через $X^n$ будем обозначать множество последовательностей длины $n$ над $X$, где $X$ --- некоторое конечное множество. Общая скрытая полу-марковская модель (ОСПММ) определяется как набор
\begin{equation}\label{chapt1_GHSMM_Def}
\lambda = \{\mathcal{S}, \mathcal{D}, A, \Pi, \mathcal{V}, B \},
\end{equation}
элементы которого описываются следующим образом.

$\mathcal{S}=\{1,...,N\}$ --- алфавит состояний дискретной полумарковской цепи, а $\mathcal{D}=\{1,...,D\}$ --- алфавит возможных длительностей состояний. Элементы декартова произведения $\mathcal{S}\times\mathcal{D}$ будем называть, следуя \cite{Murphy}, обобщенными состояниями.

$A=\{a_{(i,d)(i^\prime,d^\prime)}\}_{(i,d),(i^\prime, d^\prime)\in \mathcal{S}\times \mathcal{D}}$ --- матрица переходных вероятностей для обобщенных состояний, то есть $a_{(i,d)(i^\prime,d^\prime)}$ --- это вероятность перехода из обобщенного состояния $(i,d)$ в обобщенное состояние $(i^\prime,d^\prime)$, при этом
\begin{equation}
\label{stoch_cond}
\forall (i,d)\in \mathcal{S}\times\mathcal{D}:\;\;\; \sum\limits_{i^\prime \in S\backslash\{i\}}\sum\limits_{d^\prime\in \mathcal{D}}a_{(i,d)(i^\prime,d^\prime)}=1,
\end{equation}
$$\forall i \in \mathcal{S},\forall d,d^\prime \in \mathcal{D}:\;\;\; a_{(i,d^\prime)(i,d)}=0.$$

$\Pi=\{\pi_{i,d}\}_{(i,d)\in \mathcal{S}\times \mathcal{D}}$ --- набор исходных распределений вероятностей обобщенных состояний, т.е. $\pi_{i,d}$  --- вероятность того, что система прибывала в обобщенном состоянии $(i,d)$ до начала наблюдений.

$\mathcal{V}=\{v_1,...,v_M\}$ --- алфавит наблюдаемых символов, $$B=\{b_{i,d}(\hat{o}_1,...,\hat{o}_d)\}_{(i,d) \in \mathcal{S}\times \mathcal{D}, (\hat{o}_1,...,\hat{o}_d) \in \mathcal{V}^d}$$ --- набор распределений вероятностей наблюдений последовательностей $(\hat{o}_1,...,\hat{o}_d) \in \mathcal{V}^d$ в обобщенных состояниях.

Заметим, что текущее состояние и длительность пребывания в нем зависят как от предыдущего состояния, так и от его длительности. Частными случаями ОСПММ являются скрытая марковская модель с явно заданной плотностью длительности состояний \cite{Rabiner}, скрытая марковская модель с непрерывно изменяющейся длительностью из \cite{Levinson}, а также сегментные скрытые марковские модели, обзор которых можно найти в \cite{Ostendorf}.

Следуя Ю, будем использовать следующие обозначения: $O_{t_1:t_m}\triangleq O_{t_1},...,O_{t_m}$, $S_{t_1:t_m}\triangleq S_{t_1},...,S_{t_m}$, где $t_1,...,t_m $ --- последовательность отсчетов времени $(t_i\in \mathbb{Z})$. Далее
  $S_{t_1:t_2}=i$ означает, что система находится в состоянии $i$ на протяжении временного интервала $[t_1,t_2]$. $S_{[t_1:t_2]}=i$ свидетельствует о том, что состояние $i$ начинается в момент времени $t_1$, продолжается на протяжении временного интервала $[t_1,t_2]$ и заканчивается в момент времени $t_2$.
 Обозначение $S_{[t_1:t_2}=i$ отражает ситуацию, когда состояние $i$ начинается в момент времени $t_1$, продолжается на протяжении $[t_1,t_2]$ и необязательно заканчивается в момент времени $t_2$. Аналогично, $S_{t_1:t_2]}=i$ означает, что система находилась в состоянии $i$ на протяжении $[t_1,t_2]$, причем началось состояние $i$ необязательно в момент $t_1$, но зато известно, что в момент $t_2$ состояние $i$ закончилось.
 Под $P[\alpha | \beta]$ будем понимать вероятность события $\alpha$ при условии выполнения события $\beta$, а под  $P[\alpha\cdot \beta]$  -- совместную вероятность наблюдения событий $\alpha$ и $\beta$.

 Используя введенные обозначения, можем записать:
$$\forall (i,d), (i^\prime,d^\prime)\in \mathcal{S}\times\mathcal{D}:\;\;\; a_{(i,d)(i^\prime,d^\prime)}\triangleq P[S_{[t+1:t+d^\prime]}=i^\prime|S_{[t-d +1:t]}=i],$$
где $t$ -- момент времени, когда произошел переход из обобщенного состояния $(i,d)$ в $(i^\prime,d^\prime)$;
\begin{equation}
\nonumber
\forall t\leq 0,\forall (i,d)\in \mathcal{S}\times\mathcal{D}:\;\;\; \pi_{i,d}\triangleq P[S_{[t-d+1:t]}=i];
\end{equation}
\begin{equation}
\begin{split}
\label{eq_firstb}
\forall (i,d) \in \mathcal{S}\times \mathcal{D},\forall (o_{t+1},...,o_{t+d}) &\in V^d :\\
&b_{i,d}(o_{t+1},...,o_{t+d})\triangleq P[ o_{t+1},...,o_{t+d}|S_{[t+1:t+d]}=i].
\end{split}
\end{equation}

Описанная общая скрытая полумарковская модель может использоваться как генератор последовательности наблюдений. Генерация происходит следующим образом.

1. Первое наблюдаемое состояние $i_1$ и его длительность $d_1$ выбирается в соответствии с вектором $\Pi$. Состояние $i_1$ длится $d_1$ моментов времени.

 2. В соответстии с вероятностью $b_{i_1,d_1}(o_1,...,o_{d_1})$ генерируется частичная последовательность наблюдаемых символов $o_1,...,o_{d_1}$

3. Модель переходит в состояние $i_2$ длительностью $d_2$ в соответствии с переходной вероятностью $a_{(i_1, d_1)(i_2,d_2)}$

4. В соответстии с вероятностью $b_{i_2,d_2}(o_1,...,o_{d_2})$ генерируется частичная последовательность наблюдаемых символов $o_1,...,o_{d_2}$

5. Модель переходит в обобщенное состояние $(i_3, d_3)$ и т.д.

Работа скрытой полумарковской модели для частного случая проиллюстрирована на рис.9.

\begin{center}
  \includegraphics[height=80mm]{/part1/hsmm.png}

  Рис.9. Работа скрытой полумарковской модели
  \end{center}


Для решения прикладных задач представляют интерес частные случаи общей скрытой полумарковской модели. В частности, рассмотрим общую скрытую полумарковскую модель со следующими дополнительными условиями:

1) текущее состояние не зависит от длительности предыдущего состояния;

2) текущая длительность определяется только текущим состоянием и не зависит от предыдущего состояния и его длительности;

3) наблюдения символов выходного алфавита внутри длительности полагаются условно независимыми.

Далее будем говорить о такой модели как о скрытой полумарковской модели с относительно независимыми длительностями и наблюдениями.

Ограничения 1) -- 2) можно записать в виде:
\begin{equation}\label{eq:chapt1_GHSMM_Indep:inclus1} a_{(i,d)(j,d^\prime)}= a_{ij}\cdot p_j(d^\prime),\end{equation}
где $a_{ij}=P[S_{[t}=j|S_{t-1]}=i]$, а ограничение 3):
\begin{equation}\label{eq:chapt1_GHSMM_Indep:inclus2}b_{j,d}(O_{t+1:t+d})=\prod\limits_{\tau=t+1}^{t+d}b_j(O_\tau).\end{equation}
Аналогично (\ref{eq:chapt1_GHSMM_Indep:inclus1}), для начального распределения вероятностей состояний можно записать:
\begin{equation}
\label{eq:chapt1_GHSMM_Indep:inclus3}
 \pi_{(i,d)}= \pi_{i}\cdot p_i(d),
\end{equation}
где $\pi_{i}=P[S_{[t}=i]$ для $t\leq 0$. 